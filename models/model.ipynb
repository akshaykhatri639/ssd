{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.applications import vgg19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Conv2D, Input\n",
    "from keras.models import Model\n",
    "from functools import partial, update_wrapper\n",
    "from DataGenerator import DataGenerator\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from keras import optimizers\n",
    "from keras.metrics import sparse_categorical_accuracy, categorical_accuracy\n",
    "from keras import backend as K\n",
    "\n",
    "from losses_and_metrics import accuracy, recall, loss_with_negative_mining, wrapped_partial, compute_one_by_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 21\n",
    "aspect_ratios = [1, 2, 3, 1 / 2.0, 1 / 3.0]\n",
    "num_aspect_ratios = len(aspect_ratios)+1 # +1 for the last box with aspect_ratio 1 but bigger size\n",
    "\n",
    "# feature_sizes = [28, 14, 7]\n",
    "feature_sizes = [28, 14]\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use VGG as the base model\n",
    "model = vgg19.VGG19(include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.topology.InputLayer object at 0x7f6820676b90> (None, 224, 224, 3)\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6820676fd0> (None, 224, 224, 64)\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f6820683190> (None, 224, 224, 64)\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f6820683350> (None, 112, 112, 64)\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f67a0ca0d90> (None, 112, 112, 128)\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f67a0cb7fd0> (None, 112, 112, 128)\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f67a0c81710> (None, 56, 56, 128)\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f67a0c6be90> (None, 56, 56, 256)\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f67a0c11c50> (None, 56, 56, 256)\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f67a0c29ed0> (None, 56, 56, 256)\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f67a0bd1150> (None, 56, 56, 256)\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f67a0be6f50> (None, 28, 28, 256)\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f67a0b92190> (None, 28, 28, 512)\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f67a0ba4cd0> (None, 28, 28, 512)\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f67a0b62450> (None, 28, 28, 512)\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f67a0b4d710> (None, 28, 28, 512)\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f67a0b0d0d0> (None, 14, 14, 512)\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f67a0b204d0> (None, 14, 14, 512)\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f67a0aca8d0> (None, 14, 14, 512)\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f67a0adea50> (None, 14, 14, 512)\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f67a0af3b90> (None, 14, 14, 512)\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f67a0a9d410> (None, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "# see output shapes on all layers\n",
    "for layer in model.layers:\n",
    "    print layer, layer.output_shape\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = Conv2D(padding='same', filters=num_classes*num_aspect_ratios, kernel_size=3,\n",
    "              activation=None, name='28')(model.layers[-7].output)\n",
    "\n",
    "out2 = Conv2D(padding='same', filters=num_classes*num_aspect_ratios, kernel_size=3, \n",
    "              activation=None, name='14')(model.layers[-2].output)\n",
    "\n",
    "# out3 = Conv2D(padding='same', filters=num_classes*num_aspect_ratios, kernel_size=3,\n",
    "#               activation=None, name='7')(model.layers[-1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28, 126)\n",
      "(?, 14, 14, 126)\n"
     ]
    }
   ],
   "source": [
    "print out1.shape\n",
    "print out2.shape\n",
    "# print out3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20 # set randomly for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true Tensor(\"28_target:0\", shape=(?, ?, ?, ?), dtype=float32) y_pred Tensor(\"28/BiasAdd:0\", shape=(?, 28, 28, 126), dtype=float32)\n",
      "After reshape and slicing: y_true Tensor(\"metrics/accuracy/Slice:0\", shape=(?, ?, ?, 6), dtype=float32) y_pred Tensor(\"metrics/accuracy/Reshape:0\", shape=(?, ?, ?, 6, 21), dtype=float32)\n",
      "Final: y_true Tensor(\"metrics/accuracy/one_hot:0\", shape=(?, 21), dtype=float32) y_pred Tensor(\"metrics/accuracy/Reshape_1:0\", shape=(?, 21), dtype=float32)\n",
      "Tensor(\"metrics/recall/Squeeze:0\", dtype=int64)\n",
      "y_true Tensor(\"14_target:0\", shape=(?, ?, ?, ?), dtype=float32) y_pred Tensor(\"14/BiasAdd:0\", shape=(?, 14, 14, 126), dtype=float32)\n",
      "After reshape and slicing: y_true Tensor(\"metrics/accuracy_1/Slice:0\", shape=(?, ?, ?, 6), dtype=float32) y_pred Tensor(\"metrics/accuracy_1/Reshape:0\", shape=(?, ?, ?, 6, 21), dtype=float32)\n",
      "Final: y_true Tensor(\"metrics/accuracy_1/one_hot:0\", shape=(?, 21), dtype=float32) y_pred Tensor(\"metrics/accuracy_1/Reshape_1:0\", shape=(?, 21), dtype=float32)\n",
      "Tensor(\"metrics/recall_1/Squeeze:0\", dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "ssd_model = Model(inputs=model.input, outputs = [out1, out2])\n",
    "acc_fun = wrapped_partial(accuracy, num_aspect_ratios=num_aspect_ratios, num_classes=num_classes)\n",
    "recall_fun = wrapped_partial(recall, num_aspect_ratios=num_aspect_ratios, num_classes=num_classes)\n",
    "\n",
    "loss_fun_28 = wrapped_partial(loss_with_negative_mining, k=13, num_aspect_ratios=num_aspect_ratios, num_classes=num_classes)\n",
    "loss_fun_14 = wrapped_partial(loss_with_negative_mining, k=25, num_aspect_ratios=num_aspect_ratios, num_classes=num_classes)\n",
    "\n",
    "optim = optimizers.Adam()\n",
    "\n",
    "ssd_model.compile(optimizer=optim, \n",
    "              loss={'28': loss_fun_28, '14': loss_fun_14}, #, '7':loss_fun},\n",
    "                 metrics=[acc_fun, recall_fun])\n",
    "\n",
    "# ssd_model.load_weights(\"VGG_basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17125,)\n"
     ]
    }
   ],
   "source": [
    "data_gen = DataGenerator(data_dir='../data/VOCdevkit/VOC2012/JPEGImages/', \n",
    "                        label_dir='../data/VOCdevkit/VOC2012/Preprocessed/', \n",
    "                        num_classes=num_classes, num_aspect_ratios=num_aspect_ratios,\n",
    "                        feature_sizes=feature_sizes, \n",
    "                        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = data_gen.generate()\n",
    "# print t.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible shapes between op input and calculated input gradient.  Forward operation: loss/28_loss/TopKV2.  Input index: 1. Original input shape: (?,).  Calculated input gradient shape: ()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c5d4fb2c1bcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m ssd_model.fit_generator(generator=data_gen.generate(),steps_per_epoch=1000, epochs=20, \n\u001b[0;32m----> 2\u001b[0;31m                        validation_data=data_gen.generate(train=False), validation_steps=32)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2016\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2017\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    988\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    989\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    991\u001b[0m                 \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m                 \u001b[0;31m# Gets loss and metrics. Updates weights at each call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/optimizers.pyc\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_updates_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/optimizers.pyc\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clipnorm'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclipnorm\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   2392\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mgradients\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2393\u001b[0m     \"\"\"\n\u001b[0;32m-> 2394\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.pyc\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients)\u001b[0m\n\u001b[1;32m    607\u001b[0m                     \u001b[0;34m\"Original input shape: %s.  \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m                     \u001b[0;34m\"Calculated input gradient shape: %s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m                     % (op.name, i, t_in.shape, in_grad.shape))\n\u001b[0m\u001b[1;32m    610\u001b[0m             \u001b[0m_SetGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloop_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible shapes between op input and calculated input gradient.  Forward operation: loss/28_loss/TopKV2.  Input index: 1. Original input shape: (?,).  Calculated input gradient shape: ()"
     ]
    }
   ],
   "source": [
    "ssd_model.fit_generator(generator=data_gen.generate(),steps_per_epoch=1000, epochs=20, \n",
    "                       validation_data=data_gen.generate(train=False), validation_steps=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_model.save(\"VGG_basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saffa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
